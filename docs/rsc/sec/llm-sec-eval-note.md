---
title: 'LLMSecEval Paper Note'
date: 2025-06-04 16:48:45
tags: [paper, research]
published: false
comments: false
---

[LLMSecEval: A Dataset of Natural Language Prompts for Security Evaluations](https://ieeexplore.ieee.org/abstract/document/10174231) 中文概述

<!--more-->

1. [1. Introduction](#1-introduction)
2. [2. Related Work](#2-related-work)
3. [3. Creation of NL Prompts](#3-creation-of-nl-prompts)
4. [4. Dataset Description](#4-dataset-description)
5. [5. NL Prompts Quality Analysis](#5-nl-prompts-quality-analysis)
6. [6. Dataset Usage for Secure Code Generation](#6-dataset-usage-for-secure-code-generation)
7. [7. Limitations and Future Improvements](#7-limitations-and-future-improvements)
8. [8. Conclusion](#8-conclusion)

## 1. Introduction

论文开篇指出，大型语言模型（LLM）如 OpenAI Codex 等在代码补全和生成方面表现强大，能够根据自然语言描述自动生成代码。然而，由于这些模型训练自公开代码仓库，其中包含大量不安全的编码实践和潜在漏洞，因此 LLM 自动生成的代码可能隐含安全风险。伴随 GitHub Copilot 等工具流行，开发者越来越多地借助 LLM 来编写代码，这使得评估 LLM 所生成代码的安全性变得尤为关键。为此，作者提出并构建了**LLMSecEval**数据集，用于评估代码生成模型的安全性能。该数据集包含了**150 条自然语言（NL）提示**，每条提示描述一个可能存在安全漏洞的软件功能场景，覆盖 MITRE CWE（常见弱点枚举）排行榜中最常见的 25 类安全问题中的 18 类。此外，每个提示都附带一个对应的**安全实现代码示例**，方便将 LLM 生成的代码与安全范例进行比较。作者还开发了一个示范性应用，利用 GPT-3 和 Codex 模型对这些提示生成代码，并通过 CodeQL 工具自动扫描生成代码中的安全漏洞，以展示如何借助该数据集评估 LLM 的代码安全性。

## 2. Related Work

作者回顾了现有与代码生成评测相关的数据集和研究，发现此前的工作主要关注**功能正确性**而非**安全性**。例如，OpenAI 团队创建了 HumanEval 数据集，用于评估 Codex 所生成代码的功能正确性，每道题包含函数签名、文档字符串和单元测试。Austin 等人构建了两个数据集评估 LLM 的程序合成能力：一个包含简短的 Python 程序及相应问题描述和测试，用于检验语义正确性；另一个涵盖数学问题及其程序解答。然而，这些数据集均未针对 LLM 生成代码的**安全性**进行评估。最近，Pearce 等人研究了 Copilot 生成代码的安全问题。他们构建了包含 54 个不完整代码场景的数据集（涵盖 2021 年 CWE Top 25 中的 18 类弱点，每类 3 个场景），让 Copilot 自动补全代码，并分析结果中的安全漏洞。虽然这一研究关注代码安全，但使用的是不完整代码加注释的提示形式，而非纯自然语言描述的提示。因此，在现有文献中**缺乏**专门用于评估 LLM 代码生成安全性的 **NL 提示数据集**，这正是 LLMSecEval 所要填补的空白。

## 3. Creation of NL Prompts

LLMSecEval 数据集中的自然语言提示生成经历了三个主要步骤：

1. **数据源选择**：作者基于 Pearce 等人提供的代码场景数据集作为起点。该数据集中每个安全问题（18 种 CWE 弱点之一）都有 3 个不同的易受攻击代码场景（共 54 个场景），GitHub Copilot 为每个场景生成了 25 个代码补全，累计得到 **1084** 个完整程序（其中 C 程序 513 个、Python 程序 571 个）。作者没有直接使用全部补全结果，而是为了确保功能正确性，从每个场景的 Copilot 生成代码中筛选出**3 个功能正确**的样本。具体而言，他们按 Copilot 提供的置信排序依次检查代码样本，直到找到3个能够正确实现预期功能的实例，共选出 **162 个程序**（54 场景 × 3），作为生成 NL 提示的基础。由于原始1084个程序中约有40%含安全漏洞，这些选出的样本也很可能存在漏洞。作者在后续步骤中采取措施，避免这些漏洞细节在生成的提示中“泄露”或影响提示内容。

2. **使用 Codex 生成自然语言描述**：接下来，作者利用 OpenAI Codex 模型将上述代码程序自动翻译成相应的自然语言描述。具体采用的是 Codex 系列中功能最强的 `code-davinci-002` 模型，它在海量 GitHub 开源代码上微调过，擅长理解代码并生成描述。调用 Codex API 时，作者将每段代码作为输入，让模型输出对代码功能的NL描述。他们将输出长度上限设为 **100 个 token**，因为实验发现长度过大时模型容易生成重复冗余或无效内容。通过这种方式，Codex 为 162 个程序都生成了初步的自然语言说明。

3. **手动筛选和规范化**：Codex 输出的 162 条描述接着经过作者的人工审核与清洗，以确保每条提示都有效、清晰。首先，作者设定**包含/排除准则**筛除不合格描述：忽略空白或仅空格的输出，剔除包含大量代码片段的输出，以及删除未能准确解释输入代码功能的输出。经过这一轮过滤后，剩下 **150** 条有效的 NL 描述（意味着有 12 条被弃用)。随后，作者对这 150 条描述进行**格式润色**：去除重复啰嗦的短语、去除描述中的第一人称措辞和不必要的特殊字符、补全结尾不完整的句子，删除输出中带有的警告语句（如明确指出代码漏洞的提示，以免提示直接暴露漏洞信息）。另外，还去掉任何项目符号列表，并将描述中出现的**语言/平台特定术语**替换为更中性的表述。例如将 C 语言中的 “printf” 改为通用的 “print”，以使提示不局限于某一语言。最后，为使这些描述真正成为提示（prompt）而非简单的陈述，作者在每条描述前添加统一的前缀，例如：“**Generate \<language> code for the following:**”（“请为以下内容生成<某语言>代码：”），其中 \<language> 根据原始程序语言填入 Python 或 C。图2 展示了一个实例：给定涵盖 CWE-20（输入验证不当）的 Python 漏洞代码片段，经 Codex 描述和格式处理后生成了对应的 NL 提示。通过上述流程，作者最终产出了 **150 条高质量的自然语言提示**，可用于后续的安全性评估实验。

## 4. Dataset Description

该部分详细列出了 **LLMSecEval** 数据集的构成和属性。完整数据集以 CSV 和 JSON 格式发布，共包含 **150 条 NL 提示**，每条记录包含以下字段：

* **CWE名称**：代码潜在弱点的 CWE 类型名称，如“缓冲区溢出”、“SQL注入”等。
* **NL Prompt**：自然语言提示文本，本质上是对某个存在安全弱点的代码场景的描述。LLMSecEval 数据集覆盖了 MITRE 2021 年 CWE Top 25 中的 18 类常见弱点（占 Top 25 的大部分）。
* **Source Code Filepath**：生成该 NL 提示所依据的源码文件路径。由于这些提示都是由 Pearce 等人发布的数据中的代码片段转换而来，此字段标明对应的源代码文件位置。
* **Vulnerable（易受攻击标记）**：标记该提示是否来源于一个含已知漏洞的代码片段。根据 Pearce 等人的报告，在150条提示中有 **85 条**源自带有安全漏洞的代码。需要注意的是，作者在生成提示时**已移除了**关于漏洞细节的直接描述，因此这一标记仅供研究者了解原始代码是否存在漏洞，并不意味着提示文本包含漏洞提示信息。
* **Language（语言）**：指明生成该提示所基于的源代码使用的编程语言。LLMSecEval 提示本身经过处理已不含特定语言表述，但作者仍提供了此来源语言标签以供分析。在150条提示中，来源于 **Python** 代码的有 **83** 条，来源于 **C** 代码的有 **67** 条。
* **Quality Metrics（质量指标得分）**：作者为每条提示预先计算了4个质量评价指标的分数，包含在数据集中，方便用户筛选满足特定质量要求的提示。这4个指标是语言层面的“自然度”和“表达清晰度”，以及内容层面的“充分性”和“简洁性”，详细定义见下文第5节。
* **Secure Code Samples（安全代码示例）**：对于每条提示，数据集附带了一份对应的**安全实现代码**（以 Python 实现）。这些安全示例代码主要由作者手工编写或根据已有安全实现改进而得，以确保消除了原始不安全代码中的漏洞或不良编码实践。作者用 GitHub 的 CodeQL 静态分析工具对所有提供的安全样例进行了检查，确认其不含已知漏洞。提供这些安全代码示例的目的是便于将 LLM 生成的代码与安全基准进行比较，从而评估 LLM 输出的安全性。

上述完整数据集以及相关安全代码示例，已通过公共的 GitHub 仓库和 DOI 公开发布，供研究者获取和复现试验。

## 5. NL Prompts Quality Analysis

作者采用定量指标对 LLMSecEval 数据集中 NL 提示的质量进行了评估。他们引用 Hu 等人提出的**语言相关**和**内容相关**评价指标体系，对每条提示从不同维度打分：

* *语言相关指标*：包括 **Naturalness（自然度）** 和 **Expressiveness（表达清晰度）**。**自然度**衡量提示语句的语法和流畅程度——高自然度意味着句子无明显语法错误，语言通顺；**表达清晰度**衡量提示内容的可读性和可理解性——高表达清晰度表示句子易于理解，没有生硬或语义不清的表述。
* *内容相关指标*：包括 **Adequacy（充分性）** 和 **Conciseness（简洁性）**。**充分性**评价提示是否完整涵盖了源代码中的重要信息——高充分性表示提示提及了代码实现的所有关键功能和细节；**简洁性**考察提示是否去除了无关冗余的信息——高简洁性表示提示只保留了与代码功能相关的必要描述，没有赘述不必要背景。

作者邀请了论文的两位作者独立对每条 NL 提示在上述四个维度上进行**1 到 5 分**的评分，并严格遵循 Hu 等人文献中的评分标准定义以确保一致性。为验证人工评分的一致性，他们计算了加权 Cohen’s Kappa 系数作为**评审者间可靠性**指标。结果显示，各指标的 Kappa 值分别为：自然度 **0.98**，表达清晰度 **0.83**，充分性 **0.80**，简洁性 **0.88**。这些值均远高于0.79的可信度阈值，表明两位评审者在评价上的一致性很高，评分结果具有可信的可靠性。

评价结果表明，LLMSecEval 数据集中的提示质量整体较高，语言表述流畅清晰，内容覆盖充分且简明。具体而言：

* **自然度**：150条提示中，所有提示在自然度维度的得分都在4分或以上。大部分提示句子结构完整、语法正确，少数几条即使在格式化前存在多余空格或特殊符号等问题，也已在人工清洗时处理干净。
* **表达清晰度**：所有提示在表达清晰度上得分至少为3分，绝大多数（大部分提示）达到4分或以上。个别提示因为包含了过多具体函数名或代码实现细节，增加了理解门槛，因而得分略低，但整体上提示描述对读者而言是易读易懂的。
* **充分性**：在150条提示中，有 **138 条**在充分性维度得分不低于3分。这意味着绝大多数提示都完整提及了源代码的重要功能和安全相关要点。仅有少数（12 条左右）得分为1或2分，被认为过于抽象，未包含源代码的全部关键信息。
* **简洁性**：有 **135 条**提示在简洁性上得分不低于3分。这表明大部分提示都做到言简意赅，没有夹杂过多无关背景或内置函数原理等冗余内容。剩下少量提示简洁性得分偏低，主要因为包含了一些对于理解代码意义不大的背景说明或解释。

综上，质量分析结果证明作者生成的 NL 提示在语言和内容两方面质量都较为优秀，既**语句通顺**又**信息完整**且**言简意赅**。这为后续基于该数据集的模型评估提供了可靠的保障。

## 6. Dataset Usage for Secure Code Generation

LLMSecEval 数据集的主要目的在于推动**面向代码安全**的自动代码生成研究。作者展示了一个实际应用场景：利用该数据集来评估主流代码生成模型在安全方面的表现，即输入安全相关的 NL 提示，生成代码并检测其中漏洞。为此，作者开发了一款网络应用，整合了 OpenAI 的代码生成接口和 CodeQL 静态分析引擎。使用该应用时，用户可以上传或选择 LLMSecEval 数据集中的提示作为输入，并指定希望使用的 LLM 模型（支持 GPT-3 或 Codex）以及目标编程语言（如选择用 Python 或 C 生成代码）。应用通过 OpenAI 提供的 API 接口调用对应的模型，自动从提示生成代码。生成完成后，应用利用 GitHub 的 **CodeQL** 工具对代码进行安全扫描。CodeQL 提供一套用 **QL** 查询语言编写的漏洞检测规则，作者选用了其中针对 Top 25 CWE 中18类常见弱点的内置查询来分析生成的代码。换言之，该应用会自动检查代码中是否存在与提示相关的安全漏洞模式，并将**检测结果存储**供进一步分析。通过这个端到端示范系统，作者证明了 LLMSecEval 数据集的实用价值：研究者可以方便地将其用于对比不同 LLM（如 GPT-3 vs Codex）的代码生成在安全方面的表现，并借助静态分析工具量化和定位生成代码中的漏洞。

## 7. Limitations and Future Improvements

作者在最后讨论了本研究和数据集的局限性，并提出未来改进方向：

* **CWE 覆盖范围有限**：目前 LLMSecEval 仅涵盖了 MITRE 2021 CWE Top 25 中的 18 个弱点类型（因为原始数据源筛除了7类更偏架构层面的问题）。未来计划扩展数据集，使其覆盖 Top 25 中的所有类别，甚至根据 MITRE 每年的最新榜单持续**年度更新**提示集合。为此，作者考虑利用 CWE 官方文档中提供的示例代码来生成更多相应的 NL 提示，从而丰富数据集。
* **缺少安全测试用例**：作者打算为数据集中的每个提示设计配套的**安全单元测试**或验证用例。通过为提示场景定制输入和断言，能更好地评估生成代码在安全功能上的正确性，例如是否有效防御了提示描述的漏洞情景。当前论文未提供这部分内容，但作者认为这是进一步完善评估体系的重要方向。
* **语言无关性的权衡**：LLMSecEval 刻意将提示表述处理为不含特定编程语言痕迹，以便同一提示可用于评估不同语言的代码生成器。然而作者指出，这种语言无关性也有局限：某些 CWE 弱点与特定语言密切相关（例如内存管理漏洞多见于C/C++）。即使提示描述了这类漏洞场景，由于不同语言的特性差异，生成代码时未必都能体现相应问题。因此，用**跨语言通用**的提示去测试某些**语言特定**的安全问题可能不够准确，未来需要考虑如何处理这一情况，如针对特定语言定制提示或评估方法。

## 8. Conclusion

LLMSecEval 数据集包含 **150 条自然语言提示**，覆盖了 18 类常见软件安全弱点场景，并为每条提示提供了对应的**安全代码实现示例**。该数据集的构建弥补了当前研究在**代码生成安全评估**方面的空白，为后续工作提供了标准化的基准。通过这些语言无关的提示，研究者可以在多种编程语言上评估 LLM 的代码生成能力是否引入安全漏洞。作者开发的示例应用表明，将 LLMSecEval 与主流 LLM （如 GPT-3、Codex）和自动化分析工具（CodeQL）相结合，可以有效检测生成代码中的漏洞并量化模型的安全性能。目前数据集及配套工具已公开发布，方便社区进一步实验和改进。未来，作者计划扩展数据集涵盖更多 CWE 弱点类型，并利用该数据集持续评估**新兴主流 LLM** 的代码生成安全性，为安全可信的代码生成技术发展提供支撑。

